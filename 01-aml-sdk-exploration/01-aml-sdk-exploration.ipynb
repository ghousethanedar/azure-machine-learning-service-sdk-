{
 "nbformat": 4,
 "nbformat_minor": 2,
 "metadata": {
  "language_info": {
   "name": "python",
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "version": "3.7.3-final"
  },
  "orig_nbformat": 2,
  "file_extension": ".py",
  "mimetype": "text/x-python",
  "name": "python",
  "npconvert_exporter": "python",
  "pygments_lexer": "ipython3",
  "version": 3,
  "kernelspec": {
   "name": "python37364bitbaseconda7dbc791cb36749bd83e95b68b2a99bb5",
   "display_name": "Python 3.7.3 64-bit ('base': conda)"
  }
 },
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Table of Contents (Explore Azure Machine Learning SDK)\n",
    "____\n",
    "**1. [Workspace](#Workspace)**\n",
    "\n",
    "- 1.1 Create a Workspace and write config.json\n",
    "- 1.2 Connect to Workspace with config.json\n",
    "- 1.3 Connect to Workspace with variable\n",
    "- 1.4 Get details of the Workspace\n",
    "\n",
    "**2. [Experiment](#Experiment)**\n",
    "\n",
    "- 2.1 Create/Get Experiment\n",
    "\n",
    "**3.  [Run](#Run) **\n",
    "\n",
    "- 3.1 Create a run object in the experiment and start logging\n",
    "- 3.2 Scalar\n",
    "\n",
    "**4. [Model](#Model)**\n",
    "\n",
    "- 4.1 Register Model\n",
    "- 4.2 Download Model\n",
    "- 4.3 Delete Model\n",
    "\n",
    "**5. [ComputeTarget, RunConfiguration, and ScriptRunConfig](#ComputeTarget,RunConfiguration,andScriptRunConfig)**\n",
    "\n",
    "- 5.1 Setting up an AmlCompute (child class of ComputeTarget)\n",
    "- 5.2 Create a Compute Target\n",
    "\n",
    "**6.  [Image and Webservice](#ImageandWebservice)**\n",
    "\n",
    "**7.  [Dataset](#Dataset)**\n",
    "\n",
    "___\n",
    "\n",
    "\n"
   ],
   "execution_count": null,
   "outputs": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 1.Workspace\n",
    "\n",
    "### 1.1 Create a Workspace and write config.json"
   ],
   "execution_count": null,
   "outputs": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# from azureml.core import Workspace\n",
    "# ws = Workspace.create(name='myworkspace',\n",
    "#             subscription_id='<azure-subscription-id>',\n",
    "#             resource_group='myresourcegroup',\n",
    "#             create_resource_group=True,\n",
    "#             location='eastus2'\n",
    "#             )\n",
    "            \n",
    "# ws.write_config(path=\"./file-path\", file_name=\"ws_config.json\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 1.2 Connect to Workspace with config.json"
   ],
   "execution_count": null,
   "outputs": []
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "output_type": "stream",
     "name": "stdout",
     "text": "This notebook was created using version 1.0.2 of the Azure ML SDK\nYou are currently using version 1.0.72 of the Azure ML SDK\n\nWorkspace name: data-science\nAzure region: westeurope\nSubscription id: 29b64be4-867b-40ee-a259-b58b97bfc26f\nResource group: data-science\n"
    }
   ],
   "source": [
    "import azureml.core\n",
    "from azureml.core import Experiment, Workspace\n",
    "\n",
    "# Check core SDK version number\n",
    "print(\"This notebook was created using version 1.0.2 of the Azure ML SDK\")\n",
    "print(\"You are currently using version\", azureml.core.VERSION, \"of the Azure ML SDK\")\n",
    "print(\"\")\n",
    "\n",
    "\n",
    "ws = Workspace.from_config()\n",
    "print('Workspace name: ' + ws.name, \n",
    "      'Azure region: ' + ws.location, \n",
    "      'Subscription id: ' + ws.subscription_id, \n",
    "      'Resource group: ' + ws.resource_group, sep='\\n')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 1.3 Connect to Workspace with variable"
   ],
   "execution_count": null,
   "outputs": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# subscription_id = \"29b64be4-867b-40ee-a259-b58b97bfc26f\"\n",
    "# resource_group = \"data-science\"\n",
    "# workspace_name = \"data-science\"\n",
    "\n",
    "# ws = Workspace.get(name = workspace_name,\n",
    "#             subscription_id = subscription_id,\n",
    "#             resource_group = resource_group)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 1.4 Get details of the Workspace"
   ],
   "execution_count": null,
   "outputs": []
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "output_type": "execute_result",
     "data": {
      "text/plain": "{'id': '/subscriptions/29b64be4-867b-40ee-a259-b58b97bfc26f/resourceGroups/data-science/providers/Microsoft.MachineLearningServices/workspaces/data-science',\n 'name': 'data-science',\n 'location': 'westeurope',\n 'type': 'Microsoft.MachineLearningServices/workspaces',\n 'tags': {},\n 'sku': 'Enterprise',\n 'workspaceid': 'f3a18bbf-44bc-4e31-8355-3f8576fb0639',\n 'description': '',\n 'friendlyName': '',\n 'creationTime': '2020-04-03T09:06:14.2884876+00:00',\n 'containerRegistry': '/subscriptions/29b64be4-867b-40ee-a259-b58b97bfc26f/resourceGroups/data-science/providers/Microsoft.ContainerRegistry/registries/datascience0b4c9695',\n 'keyVault': '/subscriptions/29b64be4-867b-40ee-a259-b58b97bfc26f/resourcegroups/data-science/providers/microsoft.keyvault/vaults/datascience6891748158',\n 'applicationInsights': '/subscriptions/29b64be4-867b-40ee-a259-b58b97bfc26f/resourcegroups/data-science/providers/microsoft.insights/components/datascience9934152387',\n 'identityPrincipalId': '8fd0b713-8c03-427a-9068-1e9e62a812fc',\n 'identityTenantId': '72f988bf-86f1-41af-91ab-2d7cd011db47',\n 'identityType': 'SystemAssigned',\n 'storageAccount': '/subscriptions/29b64be4-867b-40ee-a259-b58b97bfc26f/resourcegroups/data-science/providers/microsoft.storage/storageaccounts/datascience2875229037'}"
     },
     "metadata": {},
     "execution_count": 3
    }
   ],
   "source": [
    "ws.get_details()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "___\n",
    "## 2. Experiment\n",
    "\n",
    "### 2.1 Create/Get Experiment"
   ],
   "execution_count": null,
   "outputs": []
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "output_type": "execute_result",
     "data": {
      "text/plain": "Experiment(Name: e-commerce,\nWorkspace: data-science)",
      "text/html": "<table style=\"width:100%\"><tr><th>Name</th><th>Workspace</th><th>Report Page</th><th>Docs Page</th></tr><tr><td>e-commerce</td><td>data-science</td><td><a href=\"https://ml.azure.com/experiments/e-commerce?wsid=/subscriptions/29b64be4-867b-40ee-a259-b58b97bfc26f/resourcegroups/data-science/workspaces/data-science\" target=\"_blank\" rel=\"noopener\">Link to Azure Machine Learning studio</a></td><td><a href=\"https://docs.microsoft.com/en-us/python/api/azureml-core/azureml.core.experiment.Experiment?view=azure-ml-py\" target=\"_blank\" rel=\"noopener\">Link to Documentation</a></td></tr></table>"
     },
     "metadata": {},
     "execution_count": 2
    }
   ],
   "source": [
    "experiment = Experiment(workspace=ws, name=\"e-commerce\")\n",
    "experiment"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "___\n",
    "\n",
    "## 3. Run\n",
    "\n",
    "### 3.1 Create a run object in the experiment and start logging"
   ],
   "execution_count": null,
   "outputs": []
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "run =  experiment.start_logging()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Scalar\n",
    "run.log('accuracy', 0.03)\n",
    "# List \n",
    "run.log_list(\"accuracies\", [0.6, 0.7, 0.87])\n",
    "# Row\n",
    "run.log_row(\"Y over X\", x=1, y=0.4)\n",
    "# Table \n",
    "run.log_table(\"Y over X\", {\"x\":[1, 2, 3], \"y\":[0.6, 0.7, 0.89]})"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "output_type": "stream",
     "name": "stdout",
     "text": "No Skill: ROC AUC=0.500\nLogistic: ROC AUC=0.903\n"
    },
    {
     "output_type": "display_data",
     "data": {
      "text/plain": "<Figure size 640x480 with 1 Axes>"
     },
     "metadata": {}
    }
   ],
   "source": [
    "# roc curve and auc\n",
    "from sklearn.datasets import make_classification\n",
    "from sklearn.linear_model import LogisticRegression\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.metrics import roc_curve\n",
    "from sklearn.metrics import roc_auc_score\n",
    "import matplotlib.pyplot as plt\n",
    "# generate 2 class dataset\n",
    "X, y = make_classification(n_samples=1000, n_classes=2, random_state=1)\n",
    "# split into train/test sets\n",
    "trainX, testX, trainy, testy = train_test_split(X, y, test_size=0.5, random_state=2)\n",
    "# generate a no skill prediction (majority class)\n",
    "ns_probs = [0 for _ in range(len(testy))]\n",
    "# fit a model\n",
    "model = LogisticRegression(solver='lbfgs')\n",
    "model.fit(trainX, trainy)\n",
    "# predict probabilities\n",
    "lr_probs = model.predict_proba(testX)\n",
    "# keep probabilities for the positive outcome only\n",
    "lr_probs = lr_probs[:, 1]\n",
    "# calculate scores\n",
    "ns_auc = roc_auc_score(testy, ns_probs)\n",
    "lr_auc = roc_auc_score(testy, lr_probs)\n",
    "# summarize scores\n",
    "print('No Skill: ROC AUC=%.3f' % (ns_auc))\n",
    "print('Logistic: ROC AUC=%.3f' % (lr_auc))\n",
    "# calculate roc curves\n",
    "ns_fpr, ns_tpr, _ = roc_curve(testy, ns_probs)\n",
    "lr_fpr, lr_tpr, _ = roc_curve(testy, lr_probs)\n",
    "# plot the roc curve for the model\n",
    "plt.plot(ns_fpr, ns_tpr, linestyle='--', label='No Skill')\n",
    "plt.plot(lr_fpr, lr_tpr, marker='.', label='Logistic')\n",
    "# axis labels\n",
    "plt.xlabel('False Positive Rate')\n",
    "plt.ylabel('True Positive Rate')\n",
    "# show the legend\n",
    "plt.legend()\n",
    "\n",
    "# Image\n",
    "run.log_image('ROC', path=None, plot=plt, description='')\n",
    "\n",
    "# show the plot\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Complete the run\n",
    "run.complete()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "___\n",
    "\n",
    "## 4. Model\n",
    "\n",
    "### 4.1 Register Model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {},
   "outputs": [
    {
     "output_type": "execute_result",
     "data": {
      "text/plain": "['./model/churn-model.pkl']"
     },
     "metadata": {},
     "execution_count": 25
    }
   ],
   "source": [
    "from sklearn import svm\n",
    "import joblib\n",
    "import numpy as np\n",
    "\n",
    "# customer ages\n",
    "X_train = np.array([50, 17, 35, 23, 28, 40, 31, 29, 19, 62])\n",
    "X_train = X_train.reshape(-1, 1)\n",
    "# churn y/n\n",
    "y_train = [\"yes\", \"no\", \"no\", \"no\", \"yes\", \"yes\", \"yes\", \"no\", \"no\", \"yes\"]\n",
    "\n",
    "clf = svm.SVC(gamma=0.001, C=100.)\n",
    "clf.fit(X_train, y_train)\n",
    "\n",
    "joblib.dump(value=clf, filename=\"./model/churn-model.pkl\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {},
   "outputs": [
    {
     "output_type": "stream",
     "name": "stdout",
     "text": "Registering model churn-model-test\n"
    }
   ],
   "source": [
    "from azureml.core.model import Model\n",
    "\n",
    "model = Model.register(workspace=ws, model_path=\"./model/churn-model.pkl\", model_name=\"churn-model-test\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 4.2 Download Model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {},
   "outputs": [
    {
     "output_type": "execute_result",
     "data": {
      "text/plain": "'c:\\\\Users\\\\jebaeuer\\\\Desktop\\\\repo\\\\azure-machine-learning-service\\\\churn-model.pkl'"
     },
     "metadata": {},
     "execution_count": 27
    }
   ],
   "source": [
    "from azureml.core.model import Model\n",
    "import os\n",
    "\n",
    "model = Model(workspace=ws, name=\"churn-model-test\")\n",
    "model.download(target_dir=os.getcwd())"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 4.3 Delete Model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "model.delete()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "___\n",
    "\n",
    "## 5. ComputeTarget, RunConfiguration, and ScriptRunConfig\n",
    "\n",
    "### 5.1 Setting up an AmlCompute (child class of ComputeTarget)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "metadata": {},
   "outputs": [],
   "source": [
    "from azureml.core.runconfig import RunConfiguration\n",
    "from azureml.core.compute import AmlCompute\n",
    "list_vms = AmlCompute.supported_vmsizes(workspace=ws)\n",
    "# list_vms\n",
    "compute_config = RunConfiguration()\n",
    "compute_config.target = \"amlcompute\"\n",
    "compute_config.amlcompute.vm_size = \"STANDARD_D1_V2\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "metadata": {},
   "outputs": [],
   "source": [
    "from azureml.core.conda_dependencies import CondaDependencies\n",
    "\n",
    "dependencies = CondaDependencies()\n",
    "dependencies.add_pip_package(\"scikit-learn\")\n",
    "dependencies.add_pip_package(\"numpy==1.15.4\")\n",
    "compute_config.environment.python.conda_dependencies = dependencies"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "metadata": {
    "tags": [
     "outputPrepend"
    ]
   },
   "outputs": [
    {
     "output_type": "stream",
     "name": "stdout",
     "text": " container 1ced2732ad8d\n ---> bd3673bb828c\nStep 5/15 : COPY azureml-environment-setup/99brokenproxy /etc/apt/apt.conf.d/\n ---> d903b97a5dcf\nStep 6/15 : RUN if dpkg --compare-versions `conda --version | grep -oE '[^ ]+$'` lt 4.4.11; then conda install conda==4.4.11; fi\n ---> Running in d95c6fca4cfb\nRemoving intermediate container d95c6fca4cfb\n ---> 5fb0ae5ff9bd\nStep 7/15 : COPY azureml-environment-setup/mutated_conda_dependencies.yml azureml-environment-setup/mutated_conda_dependencies.yml\n ---> 4d01357056a0\nStep 8/15 : RUN ldconfig /usr/local/cuda/lib64/stubs && conda env create -p /azureml-envs/azureml_e2e47335979ab4bbc0d2a235333de638 -f azureml-environment-setup/mutated_conda_dependencies.yml && rm -rf \"$HOME/.cache/pip\" && conda clean -aqy && CONDA_ROOT_DIR=$(conda info --root) && rm -rf \"$CONDA_ROOT_DIR/pkgs\" && find \"$CONDA_ROOT_DIR\" -type d -name __pycache__ -exec rm -rf {} + && ldconfig\n ---> Running in be94cc4c8f7c\nSolving environment: ...working... \ndone\n\u001b[91m\n\n==> WARNING: A newer version of conda exists. <==\n  current version: 4.5.11\n  latest version: 4.8.3\n\nPlease update conda by running\n\n    $ conda update -n base -c defaults conda\n\n\n\nncurses-5.9          | 1.1 MB    |            |   0% \u001b[0m\u001b[91m\nncurses-5.9          | 1.1 MB    | ###7       |  37% \u001b[0m\u001b[91m\nncurses-5.9          | 1.1 MB    | #######8   |  79% \u001b[0m\u001b[91m\nncurses-5.9          | 1.1 MB    | #########3 |  93% \u001b[0m\u001b[91m\nncurses-5.9          | 1.1 MB    | ########## | 100% \u001b[0m\u001b[91m\n\ncertifi-2020.4.5.1   | 151 KB    |            |   0% \u001b[0m\u001b[91m\ncertifi-2020.4.5.1   | 151 KB    | ########## | 100% \u001b[0m\u001b[91m\n\nca-certificates-2020 | 146 KB    |            |   0% \u001b[0m\u001b[91m\nca-certificates-2020 | 146 KB    | ########## | 100% \u001b[0m\u001b[91m\n\nlibgomp-9.2.0        | 816 KB    |            |   0% \u001b[0m\u001b[91m\nlibgomp-9.2.0        | 816 KB    | #########5 |  95% \u001b[0m\u001b[91m\nlibgomp-9.2.0        | 816 KB    | ########## | 100% \u001b[0m\u001b[91m\n\ntk-8.5.19            | 1.9 MB    |            |   0% \u001b[0m\u001b[91m\ntk-8.5.19            | 1.9 MB    | #######7   |  78% \u001b[0m\u001b[91m\ntk-8.5.19            | 1.9 MB    | #########1 |  91% \u001b[0m\u001b[91m\ntk-8.5.19            | 1.9 MB    | ########## | 100% \u001b[0m\u001b[91m\n\nopenssl-1.0.2u       | 3.2 MB    |            |   0% \u001b[0m\u001b[91m\nopenssl-1.0.2u       | 3.2 MB    | #######6   |  76% \u001b[0m\u001b[91m\nopenssl-1.0.2u       | 3.2 MB    | #########4 |  94% \u001b[0m\u001b[91m\nopenssl-1.0.2u       | 3.2 MB    | ########## | 100% \u001b[0m\u001b[91m\n\npython-3.6.2         | 19.0 MB   |            |   0% \u001b[0m\u001b[91m\npython-3.6.2         | 19.0 MB   | ##4        |  24% \u001b[0m\u001b[91m\npython-3.6.2         | 19.0 MB   | ######8    |  68% \u001b[0m\u001b[91m\npython-3.6.2         | 19.0 MB   | ########6  |  86% \u001b[0m\u001b[91m\npython-3.6.2         | 19.0 MB   | #########9 |  99% \u001b[0m\u001b[91m\npython-3.6.2         | 19.0 MB   | ########## | 100% \u001b[0m\u001b[91m\n\nlibgcc-ng-9.2.0      | 8.2 MB    |            |   0% \u001b[0m\u001b[91m\nlibgcc-ng-9.2.0      | 8.2 MB    | #######5   |  75% \u001b[0m\u001b[91m\nlibgcc-ng-9.2.0      | 8.2 MB    | #########7 |  98% \u001b[0m\u001b[91m\nlibgcc-ng-9.2.0      | 8.2 MB    | ########## | 100% \u001b[0m\u001b[91m\n\npython_abi-3.6       | 4 KB      |            |   0% \u001b[0m\u001b[91m\npython_abi-3.6       | 4 KB      | ########## | 100% \u001b[0m\u001b[91m\n\nwheel-0.34.2         | 24 KB     |            |   0% \u001b[0m\u001b[91m\nwheel-0.34.2         | 24 KB     | ########## | 100% \u001b[0m\u001b[91m\n\npip-20.0.2           | 1.0 MB    |            |   0% \u001b[0m\u001b[91m\npip-20.0.2           | 1.0 MB    | #######9   |  80% \u001b[0m\u001b[91m\npip-20.0.2           | 1.0 MB    | #########5 |  96% \u001b[0m\u001b[91m\npip-20.0.2           | 1.0 MB    | ########## | 100% \u001b[0m\u001b[91m\n\n_openmp_mutex-4.5    | 435 KB    |            |   0% \u001b[0m\u001b[91m\n_openmp_mutex-4.5    | 435 KB    | ########## | 100% \u001b[0m\u001b[91m\n\n_libgcc_mutex-0.1    | 3 KB      |            |   0% \u001b[0m\u001b[91m\n_libgcc_mutex-0.1    | 3 KB      | ########## | 100% \u001b[0m\u001b[91m\n\nxz-5.2.5             | 430 KB    |            |   0% \u001b[0m\u001b[91m\nxz-5.2.5             | 430 KB    | #########2 |  92% \u001b[0m\u001b[91m\nxz-5.2.5             | 430 KB    | ########## | 100% \u001b[0m\u001b[91m\n\nzlib-1.2.11          | 105 KB    |            |   0% \u001b[0m\u001b[91m\nzlib-1.2.11          | 105 KB    | ########## | 100% \u001b[0m\u001b[91m\n\nsetuptools-46.1.3    | 653 KB    |            |   0% \u001b[0m\u001b[91m\nsetuptools-46.1.3    | 653 KB    | ########4  |  85% \u001b[0m\u001b[91m\nsetuptools-46.1.3    | 653 KB    | ########## | 100% \u001b[0m\u001b[91m\n\nreadline-6.2         | 713 KB    |            |   0% \u001b[0m\u001b[91m\nreadline-6.2         | 713 KB    | ########3  |  84% \u001b[0m\u001b[91m\nreadline-6.2         | 713 KB    | ########## | 100% \u001b[0m\u001b[91m\n\nsqlite-3.13.0        | 4.9 MB    |            |   0% \u001b[0m\u001b[91m\nsqlite-3.13.0        | 4.9 MB    | ######5    |  65% \u001b[0m\u001b[91m\nsqlite-3.13.0        | 4.9 MB    | ########4  |  84% \u001b[0m\u001b[91m\nsqlite-3.13.0        | 4.9 MB    | #########9 | 100% \u001b[0m\u001b[91m\nsqlite-3.13.0        | 4.9 MB    | ########## | 100% \u001b[0m\nDownloading and Extracting Packages\nPreparing transaction: ...working... done\nVerifying transaction: ...working... done\nExecuting transaction: ...working... \ndone\nCollecting azureml-defaults\n  Downloading azureml_defaults-1.3.0-py3-none-any.whl (3.0 kB)\nCollecting scikit-learn\n  Downloading scikit_learn-0.22.2.post1-cp36-cp36m-manylinux1_x86_64.whl (7.1 MB)\nCollecting numpy==1.15.4\n  Downloading numpy-1.15.4-cp36-cp36m-manylinux1_x86_64.whl (13.9 MB)\nCollecting azureml-core~=1.3.0\n  Downloading azureml_core-1.3.0-py3-none-any.whl (1.2 MB)\nCollecting gunicorn==19.9.0\n  Downloading gunicorn-19.9.0-py2.py3-none-any.whl (112 kB)\nCollecting azureml-dataprep[fuse]<1.4.5a,>=1.4.3a\n  Downloading azureml_dataprep-1.4.3-py3-none-any.whl (26.7 MB)\nCollecting azureml-model-management-sdk==1.0.1b6.post1\n  Downloading azureml_model_management_sdk-1.0.1b6.post1-py2.py3-none-any.whl (130 kB)\nCollecting json-logging-py==0.2\n  Downloading json-logging-py-0.2.tar.gz (3.6 kB)\nCollecting werkzeug==0.16.1\n  Downloading Werkzeug-0.16.1-py2.py3-none-any.whl (327 kB)\nCollecting applicationinsights>=0.11.7\n  Downloading applicationinsights-0.11.9-py2.py3-none-any.whl (58 kB)\nCollecting flask==1.0.3\n  Downloading Flask-1.0.3-py2.py3-none-any.whl (92 kB)\nCollecting configparser==3.7.4\n  Downloading configparser-3.7.4-py2.py3-none-any.whl (22 kB)\nCollecting joblib>=0.11\n  Downloading joblib-0.14.1-py2.py3-none-any.whl (294 kB)\nCollecting scipy>=0.17.0\n  Downloading scipy-1.4.1-cp36-cp36m-manylinux1_x86_64.whl (26.1 MB)\nCollecting azure-graphrbac>=0.40.0\n  Downloading azure_graphrbac-0.61.1-py2.py3-none-any.whl (141 kB)\nCollecting backports.tempfile\n  Downloading backports.tempfile-1.0-py2.py3-none-any.whl (4.4 kB)\nCollecting msrest>=0.5.1\n  Downloading msrest-0.6.13-py2.py3-none-any.whl (83 kB)\nCollecting SecretStorage\n  Downloading SecretStorage-3.1.2-py3-none-any.whl (14 kB)\nCollecting azure-mgmt-authorization>=0.40.0\n  Downloading azure_mgmt_authorization-0.60.0-py2.py3-none-any.whl (82 kB)\nCollecting contextlib2\n  Downloading contextlib2-0.6.0.post1-py2.py3-none-any.whl (9.8 kB)\nCollecting adal>=1.2.0\n  Downloading adal-1.2.2-py2.py3-none-any.whl (53 kB)\nCollecting jmespath\n  Downloading jmespath-0.9.5-py2.py3-none-any.whl (24 kB)\nCollecting azure-mgmt-containerregistry>=2.0.0\n  Downloading azure_mgmt_containerregistry-2.8.0-py2.py3-none-any.whl (718 kB)\nCollecting azure-mgmt-keyvault>=0.40.0\n  Downloading azure_mgmt_keyvault-2.2.0-py2.py3-none-any.whl (89 kB)\nCollecting ndg-httpsclient\n  Downloading ndg_httpsclient-0.5.1-py3-none-any.whl (34 kB)\nCollecting docker\n  Downloading docker-4.2.0-py2.py3-none-any.whl (143 kB)\nCollecting ruamel.yaml<=0.15.89,>=0.15.35\n  Downloading ruamel.yaml-0.15.89-cp36-cp36m-manylinux1_x86_64.whl (651 kB)\nCollecting python-dateutil>=2.7.3\n  Downloading python_dateutil-2.8.1-py2.py3-none-any.whl (227 kB)\nCollecting azure-common>=1.1.12\n  Downloading azure_common-1.1.25-py2.py3-none-any.whl (12 kB)\nCollecting requests>=2.19.1\n  Downloading requests-2.23.0-py2.py3-none-any.whl (58 kB)\nCollecting msrestazure>=0.4.33\n  Downloading msrestazure-0.6.3-py2.py3-none-any.whl (40 kB)\nCollecting pytz\n  Downloading pytz-2019.3-py2.py3-none-any.whl (509 kB)\nCollecting cryptography!=1.9,!=2.0.*,!=2.1.*,!=2.2.*\n  Downloading cryptography-2.9-cp35-abi3-manylinux2010_x86_64.whl (2.7 MB)\nCollecting urllib3>=1.23\n  Downloading urllib3-1.25.8-py2.py3-none-any.whl (125 kB)\nCollecting PyJWT\n  Downloading PyJWT-1.7.1-py2.py3-none-any.whl (18 kB)\nCollecting jsonpickle\n  Downloading jsonpickle-1.4-py2.py3-none-any.whl (36 kB)\nCollecting pathspec\n  Downloading pathspec-0.8.0-py2.py3-none-any.whl (28 kB)\nCollecting azure-mgmt-resource<9.0.0,>=1.2.1\n  Downloading azure_mgmt_resource-8.0.1-py2.py3-none-any.whl (758 kB)\nCollecting pyopenssl\n  Downloading pyOpenSSL-19.1.0-py2.py3-none-any.whl (53 kB)\nCollecting azure-mgmt-storage>=1.5.0\n  Downloading azure_mgmt_storage-9.0.0-py2.py3-none-any.whl (525 kB)\nCollecting cloudpickle>=1.1.0\n  Downloading cloudpickle-1.3.0-py2.py3-none-any.whl (26 kB)\nCollecting dotnetcore2>=2.1.13\n  Downloading dotnetcore2-2.1.13-py3-none-manylinux1_x86_64.whl (29.3 MB)\nCollecting azureml-dataprep-native<15.0.0,>=14.1.0\n  Downloading azureml_dataprep_native-14.1.0-cp36-cp36m-manylinux1_x86_64.whl (1.3 MB)\nCollecting azure-identity<1.3.0,>=1.2.0\n  Downloading azure_identity-1.2.0-py2.py3-none-any.whl (58 kB)\nCollecting fusepy>=3.0.1; extra == \"fuse\"\n  Downloading fusepy-3.0.1.tar.gz (11 kB)\nCollecting liac-arff>=2.1.1\n  Downloading liac-arff-2.4.0.tar.gz (15 kB)\nCollecting dill>=0.2.7.1\n  Downloading dill-0.3.1.1.tar.gz (151 kB)\nCollecting six>=1.10\n  Downloading six-1.14.0-py2.py3-none-any.whl (10 kB)\nCollecting pandas>=0.20.2\n  Downloading pandas-1.0.3-cp36-cp36m-manylinux1_x86_64.whl (10.0 MB)\nCollecting Jinja2>=2.10\n  Downloading Jinja2-2.11.2-py2.py3-none-any.whl (125 kB)\nCollecting click>=5.1\n  Downloading click-7.1.1-py2.py3-none-any.whl (82 kB)\nCollecting itsdangerous>=0.24\n  Downloading itsdangerous-1.1.0-py2.py3-none-any.whl (16 kB)\nCollecting backports.weakref\n  Downloading backports.weakref-1.0.post1-py2.py3-none-any.whl (5.2 kB)\nCollecting isodate>=0.6.0\n  Downloading isodate-0.6.0-py2.py3-none-any.whl (45 kB)\nCollecting requests-oauthlib>=0.5.0\n  Downloading requests_oauthlib-1.3.0-py2.py3-none-any.whl (23 kB)\nRequirement already satisfied: certifi>=2017.4.17 in /azureml-envs/azureml_e2e47335979ab4bbc0d2a235333de638/lib/python3.6/site-packages (from msrest>=0.5.1->azureml-core~=1.3.0->azureml-defaults->-r /azureml-environment-setup/condaenv.pxzlsx64.requirements.txt (line 1)) (2020.4.5.1)\nCollecting jeepney>=0.4.2\n  Downloading jeepney-0.4.3-py3-none-any.whl (21 kB)\nCollecting pyasn1>=0.1.1\n  Downloading pyasn1-0.4.8-py2.py3-none-any.whl (77 kB)\nCollecting websocket-client>=0.32.0\n  Downloading websocket_client-0.57.0-py2.py3-none-any.whl (200 kB)\nCollecting idna<3,>=2.5\n  Downloading idna-2.9-py2.py3-none-any.whl (58 kB)\nCollecting chardet<4,>=3.0.2\n  Downloading chardet-3.0.4-py2.py3-none-any.whl (133 kB)\nCollecting cffi!=1.11.3,>=1.8\n  Downloading cffi-1.14.0-cp36-cp36m-manylinux1_x86_64.whl (399 kB)\nCollecting importlib-metadata\n  Downloading importlib_metadata-1.6.0-py2.py3-none-any.whl (30 kB)\nCollecting distro>=1.2.0\n  Downloading distro-1.5.0-py2.py3-none-any.whl (18 kB)\nCollecting azure-core<2.0.0,>=1.0.0\n  Downloading azure_core-1.4.0-py2.py3-none-any.whl (114 kB)\nCollecting msal<2.0.0,>=1.0.0\n  Downloading msal-1.2.0-py2.py3-none-any.whl (46 kB)\nCollecting msal-extensions~=0.1.3\n  Downloading msal_extensions-0.1.3-py2.py3-none-any.whl (9.0 kB)\nCollecting MarkupSafe>=0.23\n  Downloading MarkupSafe-1.1.1-cp36-cp36m-manylinux1_x86_64.whl (27 kB)\nCollecting oauthlib>=3.0.0\n  Downloading oauthlib-3.1.0-py2.py3-none-any.whl (147 kB)\nCollecting pycparser\n  Downloading pycparser-2.20-py2.py3-none-any.whl (112 kB)\nCollecting zipp>=0.5\n  Downloading zipp-3.1.0-py3-none-any.whl (4.9 kB)\nCollecting portalocker~=1.0\n  Downloading portalocker-1.7.0-py2.py3-none-any.whl (14 kB)\nBuilding wheels for collected packages: json-logging-py, fusepy, liac-arff, dill\n  Building wheel for json-logging-py (setup.py): started\n  Building wheel for json-logging-py (setup.py): finished with status 'done'\n  Created wheel for json-logging-py: filename=json_logging_py-0.2-py3-none-any.whl size=3923 sha256=c7f542e3f5d8e6cc7b5c7f1517b4aaaee83004d8a140d8d5ae5d1bd89eee8d2b\n  Stored in directory: /root/.cache/pip/wheels/e2/1d/52/535a274b9c2ce7d4064838f2bdb62013801281ef7d7f21e2ee\n  Building wheel for fusepy (setup.py): started\n  Building wheel for fusepy (setup.py): finished with status 'done'\n  Created wheel for fusepy: filename=fusepy-3.0.1-py3-none-any.whl size=10503 sha256=3baf5b5b0e164bd5317326934bfe9cda5dfe8bea2a9fe06d37593f7695cdd6d1\n  Stored in directory: /root/.cache/pip/wheels/21/5c/83/1dd7e8a232d12227e5410120f4374b33adeb4037473105b079\n  Building wheel for liac-arff (setup.py): started\n  Building wheel for liac-arff (setup.py): finished with status 'done'\n  Created wheel for liac-arff: filename=liac_arff-2.4.0-py3-none-any.whl size=13333 sha256=2feafe574e3a6d12df94fb174c5f71a06d52c3c52213ea708cda8314f4fcddbc\n  Stored in directory: /root/.cache/pip/wheels/ba/2a/e1/6f7be2e2ea150e2486bff64fd6f0670f4f35f4c8f31c819fb8\n  Building wheel for dill (setup.py): started\n  Building wheel for dill (setup.py): finished with status 'done'\n  Created wheel for dill: filename=dill-0.3.1.1-py3-none-any.whl size=78530 sha256=944a46ff45979552d825e1e586128c4c9953942df0db59ce20186ccc4b1500ae\n  Stored in directory: /root/.cache/pip/wheels/09/84/74/d2b4feb9ac9488bc83c475cb2cbe8e8b7d9cea8320d32f3787\nSuccessfully built json-logging-py fusepy liac-arff dill\nInstalling collected packages: idna, urllib3, chardet, requests, six, isodate, oauthlib, requests-oauthlib, msrest, python-dateutil, pycparser, cffi, cryptography, PyJWT, adal, msrestazure, azure-common, azure-graphrbac, backports.weakref, backports.tempfile, jeepney, SecretStorage, azure-mgmt-authorization, contextlib2, jmespath, azure-mgmt-containerregistry, azure-mgmt-keyvault, pyasn1, pyopenssl, ndg-httpsclient, websocket-client, docker, ruamel.yaml, pytz, zipp, importlib-metadata, jsonpickle, pathspec, azure-mgmt-resource, azure-mgmt-storage, azureml-core, gunicorn, cloudpickle, distro, dotnetcore2, azureml-dataprep-native, azure-core, msal, portalocker, msal-extensions, azure-identity, fusepy, azureml-dataprep, liac-arff, dill, numpy, pandas, azureml-model-management-sdk, json-logging-py, werkzeug, applicationinsights, MarkupSafe, Jinja2, click, itsdangerous, flask, configparser, azureml-defaults, joblib, scipy, scikit-learn\n\nSuccessfully installed Jinja2-2.11.2 MarkupSafe-1.1.1 PyJWT-1.7.1 SecretStorage-3.1.2 adal-1.2.2 applicationinsights-0.11.9 azure-common-1.1.25 azure-core-1.4.0 azure-graphrbac-0.61.1 azure-identity-1.2.0 azure-mgmt-authorization-0.60.0 azure-mgmt-containerregistry-2.8.0 azure-mgmt-keyvault-2.2.0 azure-mgmt-resource-8.0.1 azure-mgmt-storage-9.0.0 azureml-core-1.3.0 azureml-dataprep-1.4.3 azureml-dataprep-native-14.1.0 azureml-defaults-1.3.0 azureml-model-management-sdk-1.0.1b6.post1 backports.tempfile-1.0 backports.weakref-1.0.post1 cffi-1.14.0 chardet-3.0.4 click-7.1.1 cloudpickle-1.3.0 configparser-3.7.4 contextlib2-0.6.0.post1 cryptography-2.9 dill-0.3.1.1 distro-1.5.0 docker-4.2.0 dotnetcore2-2.1.13 flask-1.0.3 fusepy-3.0.1 gunicorn-19.9.0 idna-2.9 importlib-metadata-1.6.0 isodate-0.6.0 itsdangerous-1.1.0 jeepney-0.4.3 jmespath-0.9.5 joblib-0.14.1 json-logging-py-0.2 jsonpickle-1.4 liac-arff-2.4.0 msal-1.2.0 msal-extensions-0.1.3 msrest-0.6.13 msrestazure-0.6.3 ndg-httpsclient-0.5.1 numpy-1.15.4 oauthlib-3.1.0 pandas-1.0.3 pathspec-0.8.0 portalocker-1.7.0 pyasn1-0.4.8 pycparser-2.20 pyopenssl-19.1.0 python-dateutil-2.8.1 pytz-2019.3 requests-2.23.0 requests-oauthlib-1.3.0 ruamel.yaml-0.15.89 scikit-learn-0.22.2.post1 scipy-1.4.1 six-1.14.0 urllib3-1.25.8 websocket-client-0.57.0 werkzeug-0.16.1 zipp-3.1.0\n\u001b[91m\n\u001b[0m#\n# To activate this environment, use:\n# > source activate /azureml-envs/azureml_e2e47335979ab4bbc0d2a235333de638\n#\n# To deactivate an active environment, use:\n# > source deactivate\n#\n\n\nRemoving intermediate container be94cc4c8f7c\n ---> c6cb541f66aa\nStep 9/15 : ENV PATH /azureml-envs/azureml_e2e47335979ab4bbc0d2a235333de638/bin:$PATH\n ---> Running in 4d67080a2ff5\nRemoving intermediate container 4d67080a2ff5\n ---> 1a64bd5301b3\nStep 10/15 : ENV AZUREML_CONDA_ENVIRONMENT_PATH /azureml-envs/azureml_e2e47335979ab4bbc0d2a235333de638\n ---> Running in 24b6cb8671ab\nRemoving intermediate container 24b6cb8671ab\n ---> a92db99c698d\nStep 11/15 : ENV LD_LIBRARY_PATH /azureml-envs/azureml_e2e47335979ab4bbc0d2a235333de638/lib:$LD_LIBRARY_PATH\n ---> Running in c637d35d1527\nRemoving intermediate container c637d35d1527\n ---> cd4c337b134b\nStep 12/15 : COPY azureml-environment-setup/spark_cache.py azureml-environment-setup/log4j.properties /azureml-environment-setup/\n ---> e2238860ddfd\nStep 13/15 : RUN if [ $SPARK_HOME ]; then /bin/bash -c '$SPARK_HOME/bin/spark-submit  /azureml-environment-setup/spark_cache.py'; fi\n ---> Running in 8e21d4bc5d13\nRemoving intermediate container 8e21d4bc5d13\n ---> c50663a877c2\nStep 14/15 : ENV AZUREML_ENVIRONMENT_IMAGE True\n ---> Running in 7b495cce9fe2\nRemoving intermediate container 7b495cce9fe2\n ---> 713343adf6b6\nStep 15/15 : CMD [\"bash\"]\n ---> Running in b0a27d4c73c7\nRemoving intermediate container b0a27d4c73c7\n ---> 06b8ba95dcf9\nSuccessfully built 06b8ba95dcf9\nSuccessfully tagged datascience0b4c9695.azurecr.io/azureml/azureml_d39e51a6268325ae92a70da4ebcbae78:latest\n2020/04/15 06:25:44 Successfully executed container: acb_step_0\n2020/04/15 06:25:44 Executing step ID: acb_step_1. Timeout(sec): 5400, Working directory: '', Network: 'acb_default_network'\n2020/04/15 06:25:44 Pushing image: datascience0b4c9695.azurecr.io/azureml/azureml_d39e51a6268325ae92a70da4ebcbae78:latest, attempt 1\nThe push refers to repository [datascience0b4c9695.azurecr.io/azureml/azureml_d39e51a6268325ae92a70da4ebcbae78]\nb039df346e8a: Preparing\nbfd31a0d3e25: Preparing\ne40160dfb55e: Preparing\nf0308284d887: Preparing\n3aadda573796: Preparing\n1181dacdbd9e: Preparing\ne1171d4d60ca: Preparing\n6ef1a8ae63b7: Preparing\n85389f9ead9e: Preparing\nf2608f66a0e3: Preparing\n0e259b09e5f4: Preparing\n340dc32eb998: Preparing\ndf18b66efaa6: Preparing\nccdb13a20bf2: Preparing\n9513cdf4e497: Preparing\n7f083f9454c0: Preparing\n29f36b5893dc: Preparing\n1181dacdbd9e: Waiting\ne1171d4d60ca: Waiting\n6ef1a8ae63b7: Waiting\n85389f9ead9e: Waiting\nf2608f66a0e3: Waiting\n0e259b09e5f4: Waiting\n340dc32eb998: Waiting\ndf18b66efaa6: Waiting\nccdb13a20bf2: Waiting\n9513cdf4e497: Waiting\n7f083f9454c0: Waiting\n29f36b5893dc: Waiting\n3aadda573796: Pushed\ne40160dfb55e: Pushed\nf0308284d887: Pushed\nb039df346e8a: Pushed\n1181dacdbd9e: Pushed\ne1171d4d60ca: Pushed\n6ef1a8ae63b7: Pushed\n340dc32eb998: Pushed\n85389f9ead9e: Pushed\nccdb13a20bf2: Pushed\n9513cdf4e497: Pushed\n0e259b09e5f4: Pushed\n7f083f9454c0: Pushed\nf2608f66a0e3: Pushed\nbfd31a0d3e25: Pushed\n29f36b5893dc: Pushed\ndf18b66efaa6: Pushed\nlatest: digest: sha256:80bdafd3a33d0c87f7638dcc5c9bd4244278288c5e7f12dde98c46c990fe8ee6 size: 3883\n2020/04/15 06:27:05 Successfully pushed image: datascience0b4c9695.azurecr.io/azureml/azureml_d39e51a6268325ae92a70da4ebcbae78:latest\n2020/04/15 06:27:05 Step ID: acb_step_0 marked as successful (elapsed time in seconds: 151.850296)\n2020/04/15 06:27:05 Populating digests for step ID: acb_step_0...\n2020/04/15 06:27:07 Successfully populated digests for step ID: acb_step_0\n2020/04/15 06:27:07 Step ID: acb_step_1 marked as successful (elapsed time in seconds: 80.977029)\n2020/04/15 06:27:07 The following dependencies were found:\n2020/04/15 06:27:07 \n- image:\n    registry: datascience0b4c9695.azurecr.io\n    repository: azureml/azureml_d39e51a6268325ae92a70da4ebcbae78\n    tag: latest\n    digest: sha256:80bdafd3a33d0c87f7638dcc5c9bd4244278288c5e7f12dde98c46c990fe8ee6\n  runtime-dependency:\n    registry: mcr.microsoft.com\n    repository: azureml/base\n    tag: intelmpi2018.3-ubuntu16.04\n    digest: sha256:a1b514f3ba884b9a7695cbba5638933ddaf222e8ce3e8c81e8cdf861679abb05\n  git: {}\n\n\nRun ID: cb5 was successful after 3m59s\n"
    }
   ],
   "source": [
    "from azureml.core.experiment import Experiment\n",
    "from azureml.core import ScriptRunConfig\n",
    "\n",
    "script_run_config = ScriptRunConfig(source_directory=os.getcwd(), script=\"./01-aml-sdk-exploration/train.py\", run_config=compute_config)\n",
    "experiment = Experiment(workspace=ws, name=\"compute_target_test\")\n",
    "run = experiment.submit(config=script_run_config)\n",
    "run.wait_for_completion(show_output=True)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 5.2 Create a Compute Target"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "output_type": "stream",
     "name": "stdout",
     "text": "Creating\nSucceeded\nAmlCompute wait for completion finished\nMinimum number of nodes requested have been provisioned\n"
    }
   ],
   "source": [
    "from azureml.core.compute import ComputeTarget, AmlCompute\n",
    "from azureml.core.compute_target import ComputeTargetException\n",
    "\n",
    "# Choose a name for your CPU cluster\n",
    "cpu_cluster_name = \"cpu-cluster\"\n",
    "\n",
    "# Verify that cluster does not exist already\n",
    "try:\n",
    "    cpu_cluster = ComputeTarget(workspace=ws, name=cpu_cluster_name)\n",
    "    print('Found existing cluster, use it.')\n",
    "except ComputeTargetException:\n",
    "    compute_config = AmlCompute.provisioning_configuration(vm_size='STANDARD_D2_V2',\n",
    "                                                            max_nodes=4)\n",
    "    cpu_cluster = ComputeTarget.create(ws, cpu_cluster_name, compute_config)\n",
    "\n",
    "cpu_cluster.wait_for_completion(show_output=True)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "___\n",
    "\n",
    "## 6. Image and Webservice\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "output_type": "stream",
     "name": "stderr",
     "text": "ERROR - Execution script score.py doesn't exist. \n\n"
    },
    {
     "output_type": "error",
     "ename": "WebserviceException",
     "evalue": "WebserviceException:\n\tMessage: Execution script score.py doesn't exist. \n\tInnerException None\n\tErrorResponse \n{\n    \"error\": {\n        \"message\": \"Execution script score.py doesn't exist. \"\n    }\n}",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mWebserviceException\u001b[0m                       Traceback (most recent call last)",
      "\u001b[1;32m<ipython-input-9-08763d0b7192>\u001b[0m in \u001b[0;36m<module>\u001b[1;34m\u001b[0m\n\u001b[0;32m      4\u001b[0m                                                  \u001b[0mruntime\u001b[0m\u001b[1;33m=\u001b[0m\u001b[1;34m\"python\"\u001b[0m\u001b[1;33m,\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m      5\u001b[0m                                                  \u001b[0mconda_file\u001b[0m\u001b[1;33m=\u001b[0m\u001b[1;34m\"myenv.yml\"\u001b[0m\u001b[1;33m,\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m----> 6\u001b[1;33m                                                  \u001b[0mdescription\u001b[0m\u001b[1;33m=\u001b[0m\u001b[1;34m\"test-image-config\"\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m      7\u001b[0m                                                  )\n",
      "\u001b[1;32mC:\\ProgramData\\Anaconda3\\lib\\site-packages\\azureml\\core\\image\\container.py\u001b[0m in \u001b[0;36mimage_configuration\u001b[1;34m(execution_script, runtime, conda_file, docker_file, schema_file, dependencies, enable_gpu, tags, properties, description, base_image, base_image_registry, cuda_version)\u001b[0m\n\u001b[0;32m    157\u001b[0m         conf = ContainerImageConfig(execution_script, runtime, conda_file, docker_file, schema_file,\n\u001b[0;32m    158\u001b[0m                                     \u001b[0mdependencies\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0menable_gpu\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mtags\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mproperties\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mdescription\u001b[0m\u001b[1;33m,\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m--> 159\u001b[1;33m                                     base_image, base_image_registry, cuda_version=cuda_version)\n\u001b[0m\u001b[0;32m    160\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    161\u001b[0m         \u001b[1;32mreturn\u001b[0m \u001b[0mconf\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32mC:\\ProgramData\\Anaconda3\\lib\\site-packages\\azureml\\core\\image\\container.py\u001b[0m in \u001b[0;36m__init__\u001b[1;34m(self, execution_script, runtime, conda_file, docker_file, schema_file, dependencies, enable_gpu, tags, properties, description, base_image, base_image_registry, allow_absolute_path, cuda_version)\u001b[0m\n\u001b[0;32m    306\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    307\u001b[0m         \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mexecution_script_path\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mos\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mpath\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mabspath\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mos\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mpath\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mdirname\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mexecution_script\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m--> 308\u001b[1;33m         \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mvalidate_configuration\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m    309\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    310\u001b[0m     \u001b[1;32mdef\u001b[0m \u001b[0mcreate_local_debug_payload\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mself\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mworkspace\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mmodel_ids\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32mC:\\ProgramData\\Anaconda3\\lib\\site-packages\\azureml\\core\\image\\container.py\u001b[0m in \u001b[0;36mvalidate_configuration\u001b[1;34m(self)\u001b[0m\n\u001b[0;32m    447\u001b[0m                                           logger=module_logger)\n\u001b[0;32m    448\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m--> 449\u001b[1;33m         \u001b[0mvalidate_path_exists_or_throw\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mexecution_script\u001b[0m\u001b[1;33m,\u001b[0m \u001b[1;34m\"Execution script\"\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m    450\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    451\u001b[0m         \u001b[0mexecution_script_name\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mexecution_script_extension\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mos\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mpath\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0msplitext\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mos\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mpath\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mbasename\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mexecution_script\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32mC:\\ProgramData\\Anaconda3\\lib\\site-packages\\azureml\\_model_management\\_util.py\u001b[0m in \u001b[0;36mvalidate_path_exists_or_throw\u001b[1;34m(member, name, extra_message)\u001b[0m\n\u001b[0;32m    883\u001b[0m     \u001b[1;32mif\u001b[0m \u001b[1;32mnot\u001b[0m \u001b[0mos\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mpath\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mexists\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mmember\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    884\u001b[0m         raise WebserviceException(\"{0} {1} doesn't exist. {2}\".format(name, member, extra_message),\n\u001b[1;32m--> 885\u001b[1;33m                                   logger=module_logger)\n\u001b[0m\u001b[0;32m    886\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    887\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;31mWebserviceException\u001b[0m: WebserviceException:\n\tMessage: Execution script score.py doesn't exist. \n\tInnerException None\n\tErrorResponse \n{\n    \"error\": {\n        \"message\": \"Execution script score.py doesn't exist. \"\n    }\n}"
     ]
    }
   ],
   "source": [
    "from azureml.core.image import ContainerImage\n",
    "\n",
    "image_config = ContainerImage.image_configuration(execution_script=\"score.py\",\n",
    "                                                 runtime=\"python\",\n",
    "                                                 conda_file=\"myenv.yml\",\n",
    "                                                 description=\"test-image-config\"\n",
    "                                                 )"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "image = ContainerImage.create(name=\"test-image\",\n",
    "                              models=[model],\n",
    "                              image_config=image_config,\n",
    "                              workspace=ws\n",
    "                              )"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from azureml.core.webservice import AciWebservice\n",
    "\n",
    "deploy_config = AciWebservice.deploy_configuration(cpu_cores=1, memory_gb=1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from azureml.core.webservice import Webservice\n",
    "\n",
    "service = Webservice.deploy_from_image(deployment_config=deploy_config,\n",
    "                                       image=image,\n",
    "                                       name=service_name,\n",
    "                                       workspace=ws\n",
    "                                       )\n",
    "service.wait_for_deployment(show_output=True)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "___\n",
    "\n",
    "## 7. Dataset\n",
    "\n",
    "### 7.1 Tabular Dataset"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "output_type": "error",
     "ename": "ValueError",
     "evalue": "String value in path must be a url starting with \"http://\" or \"https://\".",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mValueError\u001b[0m                                Traceback (most recent call last)",
      "\u001b[1;32m<ipython-input-11-6f26819a9421>\u001b[0m in \u001b[0;36m<module>\u001b[1;34m\u001b[0m\n\u001b[0;32m      1\u001b[0m \u001b[1;32mfrom\u001b[0m \u001b[0mazureml\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mcore\u001b[0m \u001b[1;32mimport\u001b[0m \u001b[0mDataset\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m      2\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m----> 3\u001b[1;33m \u001b[0mdataset\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mDataset\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mTabular\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mfrom_delimited_files\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mpath\u001b[0m \u001b[1;33m=\u001b[0m \u001b[1;34m'customer-classification.csv'\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m      4\u001b[0m \u001b[0mdataset\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mtake\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;36m3\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mto_pandas_dataframe\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32mC:\\ProgramData\\Anaconda3\\lib\\site-packages\\azureml\\data\\_loggerfactory.py\u001b[0m in \u001b[0;36mwrapper\u001b[1;34m(*args, **kwargs)\u001b[0m\n\u001b[0;32m     76\u001b[0m             \u001b[1;32mwith\u001b[0m \u001b[0m_LoggerFactory\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mtrack_activity\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mlogger\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mfunc\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0m__name__\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mactivity_type\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mcustom_dimensions\u001b[0m\u001b[1;33m)\u001b[0m \u001b[1;32mas\u001b[0m \u001b[0mal\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m     77\u001b[0m                 \u001b[1;32mtry\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m---> 78\u001b[1;33m                     \u001b[1;32mreturn\u001b[0m \u001b[0mfunc\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m*\u001b[0m\u001b[0margs\u001b[0m\u001b[1;33m,\u001b[0m \u001b[1;33m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m     79\u001b[0m                 \u001b[1;32mexcept\u001b[0m \u001b[0mException\u001b[0m \u001b[1;32mas\u001b[0m \u001b[0me\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m     80\u001b[0m                     \u001b[1;32mif\u001b[0m \u001b[0mhasattr\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mal\u001b[0m\u001b[1;33m,\u001b[0m \u001b[1;34m'activity_info'\u001b[0m\u001b[1;33m)\u001b[0m \u001b[1;32mand\u001b[0m \u001b[0mhasattr\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0me\u001b[0m\u001b[1;33m,\u001b[0m \u001b[1;34m'error_code'\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32mC:\\ProgramData\\Anaconda3\\lib\\site-packages\\azureml\\data\\dataset_factory.py\u001b[0m in \u001b[0;36mfrom_delimited_files\u001b[1;34m(path, validate, include_path, infer_column_types, set_column_types, separator, header, partition_format)\u001b[0m\n\u001b[0;32m    210\u001b[0m             \u001b[0mheader\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mPromoteHeadersBehavior\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mNO_HEADERS\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    211\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m--> 212\u001b[1;33m         dataflow = dataprep().read_csv(_normalize_path(path),\n\u001b[0m\u001b[0;32m    213\u001b[0m                                        \u001b[0mverify_exists\u001b[0m\u001b[1;33m=\u001b[0m\u001b[1;32mFalse\u001b[0m\u001b[1;33m,\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    214\u001b[0m                                        \u001b[0minclude_path\u001b[0m\u001b[1;33m=\u001b[0m\u001b[1;32mTrue\u001b[0m\u001b[1;33m,\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32mC:\\ProgramData\\Anaconda3\\lib\\site-packages\\azureml\\data\\dataset_factory.py\u001b[0m in \u001b[0;36m_normalize_path\u001b[1;34m(path)\u001b[0m\n\u001b[0;32m    567\u001b[0m     \u001b[1;32mif\u001b[0m \u001b[0mall\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m[\u001b[0m\u001b[0misinstance\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mp\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mstr\u001b[0m\u001b[1;33m)\u001b[0m \u001b[1;32mfor\u001b[0m \u001b[0mp\u001b[0m \u001b[1;32min\u001b[0m \u001b[0mpath\u001b[0m\u001b[1;33m]\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    568\u001b[0m         \u001b[1;32mif\u001b[0m \u001b[0many\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m[\u001b[0m\u001b[1;32mnot\u001b[0m \u001b[0mhttp_pattern\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mmatch\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mp\u001b[0m\u001b[1;33m)\u001b[0m \u001b[1;32mfor\u001b[0m \u001b[0mp\u001b[0m \u001b[1;32min\u001b[0m \u001b[0mpath\u001b[0m\u001b[1;33m]\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m--> 569\u001b[1;33m             \u001b[1;32mraise\u001b[0m \u001b[0mValueError\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;34m'String value in path must be a url starting with \"http://\" or \"https://\".'\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m    570\u001b[0m         \u001b[1;32mreturn\u001b[0m \u001b[0mpath\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    571\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;31mValueError\u001b[0m: String value in path must be a url starting with \"http://\" or \"https://\"."
     ]
    }
   ],
   "source": [
    "from azureml.core import Dataset\n",
    "\n",
    "dataset = Dataset.Tabular.from_delimited_files(path = [(datastore, 'customer-classification.csv')])\n",
    "dataset.take(3).to_pandas_dataframe()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 7.2 File Dataset"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from azureml.core.dataset import Dataset\n",
    "\n",
    "url_paths = [\n",
    "            'http://yann.lecun.com/exdb/mnist/train-images-idx3-ubyte.gz',\n",
    "            'http://yann.lecun.com/exdb/mnist/train-labels-idx1-ubyte.gz',\n",
    "            'http://yann.lecun.com/exdb/mnist/t10k-images-idx3-ubyte.gz',\n",
    "            'http://yann.lecun.com/exdb/mnist/t10k-labels-idx1-ubyte.gz'\n",
    "            ]\n",
    "dataset = Dataset.File.from_files(path=url_paths)"
   ]
  }
 ]
}